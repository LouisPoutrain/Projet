{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5ca493",
   "metadata": {},
   "source": [
    "# XGBoost avec labels encodés\n",
    "Notebook pour convertir des labels non numériques en entiers (LabelEncoder), entraîner XGBoost, puis décoder les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données et inspection des labels\n",
    "\n",
    "dataset_path = \"../processed_data/csv_games_fusionnes.csv\"\n",
    "target_col = \"rb1\"  # à ajuster selon la cible à prédire\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Vérifier la présence de la cible\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_col}' est absente du dataset\")\n",
    "\n",
    "# Afficher un aperçu des labels bruts\n",
    "unique_labels = df[target_col].dropna().unique()\n",
    "print(f\"Nombre de labels uniques: {len(unique_labels)}\")\n",
    "print(\"Aperçu des labels:\", unique_labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage numérique des classes pour XGBoost\n",
    "\n",
    "# Filtrer les lignes avec label défini\n",
    "mask = df[target_col].notna()\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df.loc[mask, target_col])\n",
    "\n",
    "print(f\"Labels encodés: {len(label_encoder.classes_)} classes\")\n",
    "print(\"Mapping (label -> id):\")\n",
    "for lbl, idx in zip(label_encoder.classes_[:10], range(min(10, len(label_encoder.classes_)))):\n",
    "    print(f\"  {lbl} -> {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des features et séparation train/test\n",
    "\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "X_raw = df.loc[mask, feature_cols]\n",
    "\n",
    "# Encodage one-hot pour les features catégorielles\n",
    "X = pd.get_dummies(X_raw, drop_first=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"X train shape: {X_train.shape} | X test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b694052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement XGBoost avec labels encodés\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=num_classes,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=200,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Modèle entraîné ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08793c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation et décodage des prédictions\n",
    "\n",
    "y_pred_ids = model.predict(X_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_ids)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_ids)\n",
    "f1 = f1_score(y_test, y_pred_ids, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f} | F1-macro: {f1:.3f}\")\n",
    "print(\"\\nClassification report (labels décodés):\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
