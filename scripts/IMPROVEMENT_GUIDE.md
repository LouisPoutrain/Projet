# ğŸ¯ Guide d'AmÃ©lioration des ModÃ¨les de Draft LoL

Ce dossier contient 3 scripts avancÃ©s pour entraÃ®ner et amÃ©liorer vos modÃ¨les de prÃ©diction de draft.

## ğŸ“¦ Installation des DÃ©pendances

Avant de lancer les scripts, installez les dÃ©pendances optionnelles :

```bash
pip install lightgbm xgboost optuna
```

Ou individuellement :
```bash
pip install lightgbm  # Gradient Boosting haute performance
pip install xgboost   # Extreme Gradient Boosting
pip install optuna    # Optimisation BayÃ©sienne des hyperparamÃ¨tres
```

## ğŸš€ Scripts Disponibles

### 1. `train_and_improve.py` - Comparaison ComplÃ¨te des ModÃ¨les
**Description**: Compare LinearSVC, RandomForest, LightGBM et XGBoost avec validation croisÃ©e.

**ExÃ©cution**:
```bash
python scripts/train_and_improve.py
```

**FonctionnalitÃ©s**:
- âœ… Ã‰value 5 modÃ¨les diffÃ©rents en parallÃ¨le
- âœ… Validation croisÃ©e 5-fold pour robustesse
- âœ… Affiche mÃ©triques dÃ©taillÃ©es (Accuracy, F1, Precision, Recall)
- âœ… Sauvegarde les meilleurs modÃ¨les dans `models/improved_models/`
- âœ… Teste sur 5 cibles principales (rb1, bb2, rb2, bp1, rp1)

**Output Exemple**:
```
======================================================================
ğŸ¯ TARGET: rb1
======================================================================
  ğŸ“Š Samples: 5000 | Train: 4000 | Test: 1000
  ğŸ·ï¸  Classes: 10
  
ğŸ“ˆ Test Set Performance (80/20 split):
  LinearSVC (baseline)     | Acc: 0.456 | F1: 0.412 | Prec: 0.420 | Rec: 0.410
  LinearSVC (C=10)         | Acc: 0.478 | F1: 0.438 | Prec: 0.445 | Rec: 0.435
  RandomForest             | Acc: 0.512 | F1: 0.465 | Prec: 0.475 | Rec: 0.460
  LightGBM                 | Acc: 0.528 | F1: 0.482 | Prec: 0.490 | Rec: 0.480
  XGBoost                  | Acc: 0.535 | F1: 0.492 | Prec: 0.501 | Rec: 0.490

ğŸ”„ Cross-Validation (5-fold) pour: XGBoost
  Accuracy: 0.530 Â± 0.015
  F1-Macro: 0.487 Â± 0.018
```

---

### 2. `hyperparameter_optimizer.py` - Optimisation des HyperparamÃ¨tres
**Description**: Optimise les hyperparamÃ¨tres avec Optuna (Bayesian Optimization) ou GridSearchCV.

**ExÃ©cution**:
```bash
python scripts/hyperparameter_optimizer.py
```

**FonctionnalitÃ©s**:
- âœ… Optimisation BayÃ©sienne (Optuna) - plus rapide et efficace
- âœ… GridSearchCV en fallback si Optuna n'est pas installÃ©
- âœ… Teste 50 combinaisons d'hyperparamÃ¨tres par modÃ¨le
- âœ… Cherche les meilleurs paramÃ¨tres pour LinearSVC et RandomForest
- âœ… Utilise validation croisÃ©e 5-fold

**HyperparamÃ¨tres OptimisÃ©s**:
- **LinearSVC**: C (regularization strength) [0.01 - 100]
- **RandomForest**: 
  - n_estimators [50 - 300]
  - max_depth [5 - 50]
  - min_samples_split [2 - 20]
  - min_samples_leaf [1 - 10]

**Output Exemple**:
```
ğŸ”§ Optimisation pour: rb1
  ğŸ“Š Samples: 5000, Features: 156
  
  ğŸ” LinearSVC optimization...
    âœ… Best C: 8.4523
  
  ğŸ” RandomForest optimization...
    âœ… Best params: {'n_estimators': 250, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 2}
```

---

### 3. `ensemble_optimizer.py` - Ensemble Learning (Voting & Stacking)
**Description**: Combine plusieurs modÃ¨les avec Voting Classifier et Stacking Classifier.

**ExÃ©cution**:
```bash
python scripts/ensemble_optimizer.py
```

**FonctionnalitÃ©s**:
- âœ… Voting Classifier (soft voting) - combine prÃ©dictions par moyenne
- âœ… Stacking Classifier - utilise mÃ©ta-learner (LogisticRegression)
- âœ… Combine LinearSVC, RandomForest, AdaBoost, LightGBM, XGBoost
- âœ… Souvent meilleur que les modÃ¨les individuels
- âœ… Sauvegarde dans `models/ensemble_models/`

**Comment Ã§a marche**:
1. **Voting**: Chaque modÃ¨le vote et les votes sont moyennÃ©s
2. **Stacking**: PrÃ©dictions des modÃ¨les â†’ mÃ©tamodÃ¨le â†’ prÃ©diction finale

**Output Exemple**:
```
ğŸ¯ Ensemble Learning pour: rb1
  ğŸ“Š Samples: 4000 train, 1000 test

  ğŸ—³ï¸  Voting Classifier (soft voting)...
    âœ… Acc: 0.545 | F1: 0.502

  ğŸ“š Stacking Classifier...
    âœ… Acc: 0.552 | F1: 0.510

ğŸ“‹ RÃ‰SUMÃ‰ - MEILLEUR ENSEMBLE PAR CIBLE
======================================================================
rb1: Stacking        | F1: 0.510 | Acc: 0.552
```

---

## ğŸ“Š StratÃ©gie de Test RecommandÃ©e

### Phase 1: Comparaison (30 min)
```bash
python scripts/train_and_improve.py
```
â†’ Identifie le meilleur modÃ¨le simple

### Phase 2: Optimisation (1-2 heures)
```bash
python scripts/hyperparameter_optimizer.py
```
â†’ Affine les hyperparamÃ¨tres du meilleur modÃ¨le

### Phase 3: Ensemble (30 min)
```bash
python scripts/ensemble_optimizer.py
```
â†’ Combine les modÃ¨les optimisÃ©s

### Phase 4: IntÃ©gration
Charger les meilleurs modÃ¨les dans votre `predictor.py` :
```python
# Dans predictor.py
import pickle

# Charger l'ensemble optimal
with open('../models/ensemble_models/rb1_Stacking_ensemble.pkl', 'rb') as f:
    best_ensemble = pickle.load(f)

# Utiliser pour les prÃ©dictions
prediction = best_ensemble.predict(X_encoded)
```

---

## ğŸ›ï¸ Personalisation

### Augmenter le nombre de cibles testÃ©es
Modifier `num_targets` dans `main()`:
```python
comparator.run_full_evaluation(num_targets=10)  # au lieu de 5
```

### Augmenter le nombre d'essais d'optimisation
Modifier `n_trials` dans `run_optimization()`:
```python
optimizer.run_optimization(targets, n_trials=100)  # au lieu de 50
```

### Ajouter d'autres modÃ¨les
Dans `train_and_improve.py`, ajouter dans le dictionnaire `models`:
```python
from sklearn.neighbors import KNeighborsClassifier
models['KNN'] = KNeighborsClassifier(n_neighbors=5)
```

---

## ğŸ“ˆ MÃ©triques ExpliquÃ©es

- **Accuracy**: % de prÃ©dictions correctes
- **F1-Macro**: Moyenne harmonique par classe, utile si classes imbalancÃ©es
- **Precision**: % de prÃ©dictions positives correctes
- **Recall**: % de vrais positifs dÃ©tectÃ©s
- **Cross-Validation Std**: Variance - plus bas = plus stable

---

## âœ… Checklist de RÃ©sultats

AprÃ¨s avoir exÃ©cutÃ© les 3 scripts, vous devriez avoir:
- [ ] `models/improved_models/` avec les meilleurs modÃ¨les simples
- [ ] Rapports de validation croisÃ©e pour chaque cible
- [ ] `models/ensemble_models/` avec Voting et Stacking
- [ ] Identification du meilleur modÃ¨le par cible

---

## ğŸ”— IntÃ©gration avec Roles.py

Pour utiliser les modÃ¨les amÃ©liorÃ©s dans votre script principal:

1. **Charger les modÃ¨les sauvegardÃ©s** plutÃ´t que les rÃ©entraÃ®ner
2. **Remplacer LinearSVC par le meilleur modÃ¨le** dans `predictor.py`
3. **Garder le cache** pour les modÃ¨les amÃ©liorÃ©s

```python
# Dans predictor.py, remplacer le modÃ¨le LinearSVC
model_dir = "../models/ensemble_models"  # ou improved_models
# Charger le modÃ¨le prÃ©-optimisÃ©
```

---

## ğŸ› DÃ©pannage

**"ModuleNotFoundError: No module named 'lightgbm'"**
â†’ Installer: `pip install lightgbm`

**"Erreur: DonnÃ©es insuffisantes pour rb1"**
â†’ VÃ©rifier que `csv_games_fusionnes.csv` contient assez de donnÃ©es

**Script lent?**
â†’ RÃ©duire `num_targets` ou `n_trials` pour test rapide

---

## ğŸ“ Notes

- Les modÃ¨les sont sauvegardÃ©s au format pickle
- Validation croisÃ©e 5-fold = plus robuste mais plus lent
- Ensemble Learning est gÃ©nÃ©ralement meilleur qu'un seul modÃ¨le
- Temps d'exÃ©cution typique:
  - `train_and_improve.py`: 5-10 min
  - `hyperparameter_optimizer.py`: 30-60 min
  - `ensemble_optimizer.py`: 5-15 min
